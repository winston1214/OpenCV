{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Haar cascades\n",
    "- 머신러닝 기반의 object 검출 알고리즘\n",
    "- 특징 벡터를 만들기 위해 하르 특징 사용\n",
    "    - 하르 특징\n",
    "        - 영상의 작은 패치들의 간단한 합과 차"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 통합 영상\n",
    "Area of the rectangle **ABCD = AC - (AB+AD-AA)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(191, 3, 212, 212)\n",
      "(200, 9, 212, 212)\n",
      "(198, 8, 212, 212)\n",
      "(203, 17, 212, 212)\n",
      "(201, 13, 212, 212)\n",
      "(206, 26, 212, 212)\n",
      "(209, 24, 212, 212)\n",
      "(200, 25, 212, 212)\n",
      "(185, 25, 239, 239)\n",
      "(203, 41, 200, 200)\n",
      "(180, 27, 230, 230)\n",
      "(196, 39, 205, 205)\n",
      "(154, 143, 109, 109)\n",
      "(155, 141, 110, 110)\n",
      "(158, 139, 111, 111)\n",
      "(161, 139, 112, 112)\n",
      "(165, 138, 109, 109)\n",
      "(171, 139, 109, 109)\n",
      "(172, 136, 111, 111)\n",
      "(176, 136, 110, 110)\n",
      "(176, 135, 112, 112)\n",
      "(182, 133, 110, 110)\n",
      "(183, 130, 112, 112)\n",
      "(191, 128, 109, 109)\n",
      "(192, 125, 110, 110)\n",
      "(194, 124, 113, 113)\n",
      "(199, 119, 109, 109)\n",
      "(198, 115, 112, 112)\n",
      "(196, 108, 113, 113)\n",
      "(200, 105, 108, 108)\n",
      "(197, 98, 114, 114)\n",
      "(203, 100, 105, 105)\n",
      "(202, 100, 107, 107)\n",
      "(201, 97, 112, 112)\n",
      "(202, 101, 108, 108)\n",
      "(201, 98, 108, 108)\n",
      "(201, 97, 108, 108)\n",
      "(201, 64, 154, 154)\n",
      "(217, 77, 138, 138)\n",
      "(211, 77, 152, 152)\n",
      "(209, 80, 156, 156)\n",
      "(217, 90, 144, 144)\n",
      "(214, 90, 147, 147)\n",
      "(222, 98, 133, 133)\n",
      "(226, 102, 133, 133)\n",
      "(226, 99, 138, 138)\n",
      "(222, 98, 144, 144)\n",
      "(217, 96, 147, 147)\n",
      "(208, 86, 163, 163)\n",
      "(212, 90, 155, 155)\n",
      "(227, 103, 133, 133)\n",
      "(208, 89, 157, 157)\n",
      "(215, 93, 139, 139)\n",
      "(217, 91, 133, 133)\n",
      "(149, 39, 147, 147)\n",
      "(151, 38, 141, 141)\n",
      "(148, 40, 143, 143)\n",
      "(149, 39, 144, 144)\n",
      "(148, 39, 144, 144)\n",
      "(147, 39, 145, 145)\n",
      "(147, 37, 147, 147)\n",
      "(146, 40, 144, 144)\n",
      "(141, 38, 147, 147)\n",
      "(141, 38, 144, 144)\n",
      "(140, 39, 144, 144)\n",
      "(132, 38, 148, 148)\n",
      "(129, 39, 148, 148)\n",
      "(125, 41, 154, 154)\n",
      "(127, 48, 145, 145)\n",
      "(126, 53, 139, 139)\n",
      "(123, 58, 145, 145)\n",
      "(124, 68, 141, 141)\n",
      "(123, 74, 138, 138)\n",
      "(121, 78, 141, 141)\n",
      "(121, 79, 140, 140)\n",
      "(120, 78, 141, 141)\n",
      "(122, 81, 137, 137)\n",
      "(122, 83, 136, 136)\n",
      "(123, 78, 140, 140)\n",
      "(122, 81, 141, 141)\n",
      "(123, 83, 138, 138)\n",
      "(123, 86, 136, 136)\n"
     ]
    }
   ],
   "source": [
    "face_cascade = cv2.CascadeClassifier('cascade_files/haarcascade_frontalface_alt.xml')  # face detection xml\n",
    " \n",
    "cap = cv2.VideoCapture('img/bruno.avi') \n",
    "scaling_factor = 0.5\n",
    "size = (int(cap.get(3)),int(cap.get(4)))\n",
    "# result = cv2.VideoWriter('avi_output/face_bruno.avi',cv2.VideoWriter_fourcc(*'MJPG'),10,size) # save code\n",
    "while True: \n",
    "    ret, frame = cap.read() \n",
    "    frame = cv2.resize(frame, None, fx=1, \n",
    " fy=1, interpolation=cv2.INTER_AREA)\n",
    " \n",
    "    face_rects = face_cascade.detectMultiScale(frame, scaleFactor=1.3, minNeighbors=3)  # 현 크기보다 1.3배 큰 사각형 그리기\n",
    "    for (x,y,w,h) in face_rects: \n",
    "        cv2.rectangle(frame, (x,y), (x+w,y+h), (0,255,0), 3) \n",
    "        print((x,y,w,h))\n",
    " \n",
    "    cv2.imshow('Face Detector', frame)\n",
    "#     result.write(frame)\n",
    " \n",
    "    c = cv2.waitKey(1) \n",
    "    if c == 27: \n",
    "        break \n",
    "\n",
    "cap.release()\n",
    "# result.release()\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 얼굴에 마스크 씌우기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- cv2.threshold(src,thresh,maxval,type) -> thresh = 임계값, maxval = 임계값을 넘었을 때 적용할 value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('cascade_files/haarcascade_frontalface_alt.xml')  # face detection xml\n",
    "face_mask = cv2.imread('img/mask_hannibal.jpg')\n",
    "h_mask,w_mask = face_mask.shape[:2]\n",
    "\n",
    "if face_cascade.empty():\n",
    "    raise IOError('Unable to load the face cascade classifier xml file')\n",
    "\n",
    "cap = cv2.VideoCapture('img/bruno.avi')\n",
    "scaling_factor = 0.5\n",
    "\n",
    "while True:\n",
    "    ret,frame = cap.read()\n",
    "    frame = cv2.resize(frame,None,fx = scaling_factor,fy=scaling_factor,interpolation=cv2.INTER_AREA)\n",
    "    face_rects = face_cascade.detectMultiScale(frame,scaleFactor = 1.3,minNeighbors=3) # detect to face\n",
    "    for (x,y,w,h) in face_rects:\n",
    "        if h<=0 or w<=0: pass\n",
    "        # Adjust the height and weight parameters depending on the sizes and the locations. \n",
    "        \n",
    "        h,w = int(1.4*h),int(1.0*w)\n",
    "        y -= int(0.1*h)\n",
    "        x = int(x)\n",
    "        \n",
    "        # Extract the region of interest from the image \n",
    "        frame_roi = frame[y:y+h, x:x+w] # roi 영역 추출\n",
    "        face_mask_small = cv2.resize(face_mask,(w,h),interpolation=cv2.INTER_AREA)\n",
    "        \n",
    "        # Convert colot image to grayscale and threshold it\n",
    "        gray_mask = cv2.cvtColor(face_mask_small,cv2.COLOR_BGR2GRAY) # convert gray\n",
    "        ret,mask = cv2.threshold(gray_mask,180,255,cv2.THRESH_BINARY_INV) # 배경이 흰색이므로 180이상을 0으로 나머지는 255로\n",
    "        \n",
    "        # create an inverse mask\n",
    "        mask_inv = cv2.bitwise_not(mask)\n",
    "        \n",
    "        try:\n",
    "            # use the mask to extract the face mask region of interest\n",
    "            masked_face = cv2.bitwise_and(face_mask_small, face_mask_small, mask=mask) \n",
    "            # Use the inverse mask to get the remaining part of the image \n",
    "            masked_frame = cv2.bitwise_and(frame_roi, frame_roi, mask=mask_inv) \n",
    "        except cv2.error as e:\n",
    "#             print('Ignoring arithmentic exceptions: '+str(e))\n",
    "            break\n",
    "        \n",
    "        frame[y:y+h,x:x+w] = cv2.add(masked_face,masked_frame)\n",
    "    cv2.imshow('face detector',frame)\n",
    "    \n",
    "    c = cv2.waitKey(1)\n",
    "    if c == 27:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eye detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### faces = face_cascade.detectMultiScale(gray,scaleFactor = 1.3,minNeighbors = 1) \n",
    "-  minNeighbors = batch_size와 비슷한 의미\n",
    "- 작게 잡을 수록 더 세밀하게 scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('cascade_files/haarcascade_frontalface_alt.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('cascade_files/haarcascade_eye.xml')\n",
    "if face_cascade.empty():\n",
    "    raise IOError('Unable to load the face cascade classifier xml file')\n",
    "if eye_cascade.empty():\n",
    "    raise IOError('Unable to load the eye cascade classifier xml file')\n",
    "cap = cv2.VideoCapture('img/bruno.avi')\n",
    "ds_factor = 0.5\n",
    "size = (int(cap.get(3)),int(cap.get(4)))\n",
    "result = cv2.VideoWriter('avi_output/eye_bruno.avi',cv2.VideoWriter_fourcc(*'MJPG'),10,size) # save code\n",
    "while True:\n",
    "    ret,frame = cap.read()\n",
    "    frame = cv2.resize(frame,None,fx=ds_factor,fy=ds_factor,interpolation=cv2.INTER_AREA)\n",
    "    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray,scaleFactor = 1.3,minNeighbors = 1) \n",
    "   \n",
    "    for (x,y,w,h) in faces:\n",
    "        roi_gray = gray[y:y+h,x:x+w]\n",
    "        roi_color = frame[y:y+h,x:x+w]\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "        for (x_eye,y_eye,w_eye,h_eye) in eyes:\n",
    "            center = (int(x_eye + 0.5*w_eye),int(y_eye+0.5*h_eye))\n",
    "            radius = int(0.3*(w_eye + h_eye))\n",
    "            color = (0,255,0)\n",
    "            thickness = 3\n",
    "            cv2.circle(roi_color,center,radius,color,thickness)\n",
    "    cv2.imshow('Eye detector',frame)\n",
    "    result.write(frame)\n",
    "    c = cv2.waitKey(1)\n",
    "    if c == 27:\n",
    "        break\n",
    "result.release()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ear Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_ear_cascade = cv2.CascadeClassifier('cascade_files/haarcascade_mcs_leftear.xml')\n",
    "right_ear_cascade = cv2.CascadeClassifier('cascade_files/haarcascade_mcs_rightear.xml')\n",
    "\n",
    "if left_ear_cascade.empty():\n",
    "    raise IOError('Unable to load the left ear cascade classifier xml file')\n",
    "if right_ear_cascade.empty():\n",
    "    raise IOError('Unable to load the right ear cascade classifier xml file')\n",
    "\n",
    "cap = cv2.VideoCapture('img/bruno.avi')\n",
    "scaling_factor = 0.5\n",
    "\n",
    "while True:\n",
    "    \n",
    "    ret,frame = cap.read()\n",
    "    frame = cv2.resize(frame,None,fx = scaling_factor,fy = scaling_factor,interpolation = cv2.INTER_AREA)\n",
    "    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    left_ear = left_ear_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=3)\n",
    "    right_ear = right_ear_cascade.detectMultiScale(gray,scaleFactor=1.3,minNeighbors=3)\n",
    "    \n",
    "    for (x,y,w,h) in left_ear:\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),3)\n",
    "    for (x,y,w,h) in right_ear:\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),3)\n",
    "        \n",
    "    cv2.imshow('Ear detector',frame)\n",
    "    c= cv2.waitKey(1)\n",
    "    if c== 27:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sample 영상에서 귀를 잘 못찾음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mouth Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mouth_cascade = cv2.CascadeClassifier('cascade_files/haarcascade_mcs_mouth.xml')\n",
    "\n",
    "\n",
    "if mouth_cascade.empty():\n",
    "    raise IOError('Unable to load the left mouth cascade classifier xml file')\n",
    "\n",
    "cap = cv2.VideoCapture('img/bruno.avi')\n",
    "scaling_factor = 0.5\n",
    "\n",
    "while True:\n",
    "    \n",
    "    ret,frame = cap.read()\n",
    "    frame = cv2.resize(frame,None,fx = scaling_factor,fy = scaling_factor,interpolation = cv2.INTER_AREA)\n",
    "    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    mouth_rects = mouth_cascade.detectMultiScale(gray, scaleFactor=1.7, minNeighbors=3)\n",
    "    \n",
    "    \n",
    "    for (x,y,w,h) in mouth_rects:\n",
    "#         y = int(y-0.15*h) # why..?\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),3)\n",
    "        break\n",
    "        \n",
    "    cv2.imshow('Mouth detector',frame)\n",
    "    c= cv2.waitKey(1)\n",
    "    if c== 27:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
