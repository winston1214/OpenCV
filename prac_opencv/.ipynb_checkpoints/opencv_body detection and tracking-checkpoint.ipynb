{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Haar cascades\n",
    "- 머신러닝 기반의 object 검출 알고리즘\n",
    "- 특징 벡터를 만들기 위해 하르 특징 사용\n",
    "    - 하르 특징\n",
    "        - 영상의 작은 패치들의 간단한 합과 차"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 통합 영상\n",
    "Area of the rectangle **ABCD = AC - (AB+AD-AA)**"
   ]
  },
  {
   "attachments": {
    "bbox.PNG": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![bbox.PNG](attachment:bbox.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 얼굴 인식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('cascade_files/haarcascade_frontalface_alt.xml')  # face detection xml\n",
    " \n",
    "cap = cv2.VideoCapture('img/bruno.avi') \n",
    "scaling_factor = 0.5\n",
    "size = (int(cap.get(3)),int(cap.get(4)))\n",
    "result = cv2.VideoWriter('avi_output/face_bruno.avi',cv2.VideoWriter_fourcc(*'MJPG'),10,size) # save code\n",
    "while True: \n",
    "    ret, frame = cap.read() \n",
    "    frame = cv2.resize(frame, None, fx=1, \n",
    " fy=1, interpolation=cv2.INTER_AREA)\n",
    " \n",
    "    face_rects = face_cascade.detectMultiScale(frame, scaleFactor=1.3, minNeighbors=3)  # 현 크기보다 1.3배 큰 사각형 그리기\n",
    "    for (x,y,w,h) in face_rects: \n",
    "        cv2.rectangle(frame, (x,y), (x+w,y+h), (0,255,0), 3) \n",
    " \n",
    "    cv2.imshow('Face Detector', frame)\n",
    "    result.write(frame)\n",
    " \n",
    "    c = cv2.waitKey(1) \n",
    "    if c == 27: \n",
    "        break \n",
    "\n",
    "cap.release()\n",
    "result.release()\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 얼굴에 마스크 씌우기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- cv2.threshold(src,thresh,maxval,type) -> thresh = 임계값, maxval = 임계값을 넘었을 때 적용할 value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(3.4.2) C:\\Miniconda3\\conda-bld\\opencv-suite_1534379934306\\work\\modules\\imgproc\\src\\resize.cpp:4044: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-92de1dc2794f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaling_factor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscaling_factor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mINTER_AREA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mface_rects\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mface_cascade\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscaleFactor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mminNeighbors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# detect to face\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mface_rects\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(3.4.2) C:\\Miniconda3\\conda-bld\\opencv-suite_1534379934306\\work\\modules\\imgproc\\src\\resize.cpp:4044: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n"
     ]
    }
   ],
   "source": [
    "face_cascade = cv2.CascadeClassifier('cascade_files/haarcascade_frontalface_alt.xml')  # face detection xml\n",
    "face_mask = cv2.imread('img/mask_hannibal.jpg')\n",
    "h_mask,w_mask = face_mask.shape[:2]\n",
    "\n",
    "if face_cascade.empty():\n",
    "    raise IOError('Unable to load the face cascade classifier xml file')\n",
    "\n",
    "cap = cv2.VideoCapture('img/bruno.avi')\n",
    "scaling_factor = 0.5\n",
    "\n",
    "while True:\n",
    "    ret,frame = cap.read()\n",
    "    frame = cv2.resize(frame,None,fx = scaling_factor,fy=scaling_factor,interpolation=cv2.INTER_AREA)\n",
    "    face_rects = face_cascade.detectMultiScale(frame,scaleFactor = 1.3,minNeighbors=3) # detect to face\n",
    "    for (x,y,w,h) in face_rects:\n",
    "        if h<=0 or w<=0: pass\n",
    "        # Adjust the height and weight parameters depending on the sizes and the locations. \n",
    "        \n",
    "        h,w = int(1.4*h),int(1.0*w)\n",
    "        y -= int(0.1*h)\n",
    "        x = int(x)\n",
    "        \n",
    "        # Extract the region of interest from the image \n",
    "        frame_roi = frame[y:y+h, x:x+w] # roi 영역 추출\n",
    "        face_mask_small = cv2.resize(face_mask,(w,h),interpolation=cv2.INTER_AREA)\n",
    "        \n",
    "        # Convert colot image to grayscale and threshold it\n",
    "        gray_mask = cv2.cvtColor(face_mask_small,cv2.COLOR_BGR2GRAY) # convert gray\n",
    "        ret,mask = cv2.threshold(gray_mask,180,255,cv2.THRESH_BINARY_INV) # 배경이 흰색이므로 180이상을 0으로 나머지는 255로\n",
    "        \n",
    "        # create an inverse mask\n",
    "        mask_inv = cv2.bitwise_not(mask)\n",
    "        \n",
    "        try:\n",
    "            # use the mask to extract the face mask region of interest\n",
    "            masked_face = cv2.bitwise_and(face_mask_small, face_mask_small, mask=mask) \n",
    "            # Use the inverse mask to get the remaining part of the image \n",
    "            masked_frame = cv2.bitwise_and(frame_roi, frame_roi, mask=mask_inv) \n",
    "        except cv2.error as e:\n",
    "#             print('Ignoring arithmentic exceptions: '+str(e))\n",
    "            break\n",
    "        \n",
    "        frame[y:y+h,x:x+w] = cv2.add(masked_face,masked_frame)\n",
    "    cv2.imshow('face detector',frame)\n",
    "    \n",
    "    c = cv2.waitKey(1)\n",
    "    if c == 27:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 눈 탐지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### faces = face_cascade.detectMultiScale(gray,scaleFactor = 1.3,minNeighbors = 1) \n",
    "-  minNeighbors = batch_size와 비슷한 의미\n",
    "- 작게 잡을 수록 더 세밀하게 scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('cascade_files/haarcascade_frontalface_alt.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('cascade_files/haarcascade_eye.xml')\n",
    "if face_cascade.empty():\n",
    "    raise IOError('Unable to load the face cascade classifier xml file')\n",
    "if eye_cascade.empty():\n",
    "    raise IOError('Unable to load the eye cascade classifier xml file')\n",
    "cap = cv2.VideoCapture('bruno.avi')\n",
    "ds_factor = 0.5\n",
    "size = (int(cap.get(3)),int(cap.get(4)))\n",
    "result = cv2.VideoWriter('avi_output/eye_bruno.avi',cv2.VideoWriter_fourcc(*'MJPG'),10,size) # save code\n",
    "while True:\n",
    "    ret,frame = cap.read()\n",
    "    frame = cv2.resize(frame,None,fx=ds_factor,fy=ds_factor,interpolation=cv2.INTER_AREA)\n",
    "    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray,scaleFactor = 1.3,minNeighbors = 1) \n",
    "   \n",
    "    for (x,y,w,h) in faces: # 얼굴 뽑고\n",
    "        roi_gray = gray[y:y+h,x:x+w]\n",
    "        roi_color = frame[y:y+h,x:x+w]\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "        for (x_eye,y_eye,w_eye,h_eye) in eyes: # 눈 뽑는다\n",
    "            center = (int(x_eye + 0.5*w_eye),int(y_eye+0.5*h_eye))\n",
    "            radius = int(0.3*(w_eye + h_eye))\n",
    "            color = (0,255,0)\n",
    "            thickness = 3\n",
    "            cv2.circle(roi_color,center,radius,color,thickness)\n",
    "    cv2.imshow('Eye detector',frame)\n",
    "    result.write(frame)\n",
    "    c = cv2.waitKey(1)\n",
    "    if c == 27:\n",
    "        break\n",
    "        \n",
    "result.release()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
